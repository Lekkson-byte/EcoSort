# EcoSort AI - Project Structure

Complete overview of the project file organization and what each file does.

## ğŸ“ Root Directory Structure

```
ecosort/
â”œâ”€â”€ README.md                    # Main project documentation
â”œâ”€â”€ LICENSE                      # MIT License
â”œâ”€â”€ SETUP.md                     # Installation & setup guide
â”œâ”€â”€ CONTRIBUTING.md              # Contribution guidelines
â”œâ”€â”€ PROJECT_STRUCTURE.md         # This file
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ .gitignore                   # Git ignore rules
â”‚
â”œâ”€â”€ ecosort_model.py            # Core ML model implementation
â”œâ”€â”€ ecosort_demo.py             # Interactive demo script
â”œâ”€â”€ data_preparation.py         # Dataset download & setup
â”‚
â”œâ”€â”€ data/                        # Dataset directory (gitignored)
â”‚   â”œâ”€â”€ train/                   # Training images
â”‚   â”œâ”€â”€ validation/              # Validation images
â”‚   â”œâ”€â”€ test/                    # Test images
â”‚   â”œâ”€â”€ dataset_info.json        # Dataset metadata
â”‚   â””â”€â”€ .gitkeep                 # Keep directory in Git
â”‚
â”œâ”€â”€ models/                      # Saved models (gitignored)
â”‚   â”œâ”€â”€ ecosort_best_model.h5    # Best trained model
â”‚   â”œâ”€â”€ mobilenet_v1.h5          # MobileNet variant
â”‚   â””â”€â”€ .gitkeep                 # Keep directory in Git
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks (optional)
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_model_training.ipynb
â”‚   â””â”€â”€ 03_evaluation.ipynb
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_model.py
â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â””â”€â”€ test_predictions.py
â”‚
â”œâ”€â”€ docs/                        # Additional documentation
â”‚   â”œâ”€â”€ api_documentation.md
â”‚   â”œâ”€â”€ model_architecture.md
â”‚   â””â”€â”€ deployment_guide.md
â”‚
â””â”€â”€ assets/                      # Project assets
    â”œâ”€â”€ images/
    â”‚   â”œâ”€â”€ logo.png
    â”‚   â”œâ”€â”€ banner.jpg
    â”‚   â””â”€â”€ screenshots/
    â””â”€â”€ diagrams/
        â”œâ”€â”€ architecture.png
        â””â”€â”€ workflow.png
```

---

## ğŸ“„ File Descriptions

### Core Python Files

#### `ecosort_model.py`
**Purpose**: Main model implementation  
**Key Classes**: 
- `EcoSortModel` - CNN model class with training/prediction
**Functions**:
- `build_custom_cnn()` - Custom CNN architecture
- `build_mobilenet()` - Transfer learning with MobileNetV2
- `train()` - Model training pipeline
- `predict()` - Image classification
- `evaluate()` - Model evaluation

**Usage**:
```bash
python ecosort_model.py                    # Initialize model
python ecosort_model.py --train            # Train model
python ecosort_model.py --evaluate         # Evaluate model
```

#### `ecosort_demo.py`
**Purpose**: Interactive command-line demo  
**Key Functions**:
- `simulate_prediction()` - Demo prediction (replace with real model)
- `get_recycling_instructions()` - Location-based rules
- `print_results()` - Formatted output display

**Usage**:
```bash
python ecosort_demo.py --image waste.jpg
python ecosort_demo.py --image can.jpg --location "Portland, OR"
python ecosort_demo.py --image bottle.jpg --save-results
```

#### `data_preparation.py`
**Purpose**: Dataset downloading and organization  
**Key Classes**:
- `DatasetDownloader` - Handles dataset downloads
**Functions**:
- `download_trashnet()` - Download TrashNet dataset
- `download_taco()` - Instructions for TACO dataset
- `setup_kaggle_dataset()` - Kaggle dataset setup
- `organize_dataset_structure()` - Create folder structure

**Usage**:
```bash
python data_preparation.py --download-trashnet
python data_preparation.py --setup-structure
```

---

### Configuration Files

#### `requirements.txt`
**Purpose**: Python package dependencies  
**Contains**:
- TensorFlow/Keras for ML
- OpenCV for image processing
- NumPy, Pandas for data handling
- Flask for API (future deployment)

#### `.gitignore`
**Purpose**: Exclude files from Git  
**Ignores**:
- Large model files (*.h5)
- Dataset images
- Python cache files
- Environment variables

---

### Documentation Files

#### `README.md`
**Purpose**: Main project documentation  
**Sections**:
- Project summary
- Background and motivation
- How to use
- Data sources and AI methods
- Challenges and limitations
- Future roadmap
- Acknowledgments

#### `SETUP.md`
**Purpose**: Detailed installation guide  
**Sections**:
- Prerequisites
- Installation steps
- Dataset setup
- Training instructions
- Demo usage
- Troubleshooting

#### `CONTRIBUTING.md`
**Purpose**: Contribution guidelines  
**Sections**:
- How to contribute
- Code style guide
- Pull request process
- Community guidelines

#### `LICENSE`
**Purpose**: MIT License terms  
**Includes**: Third-party dataset licenses

---

## ğŸ“Š Data Directory Structure

```
data/
â”œâ”€â”€ train/                       # 70% of data
â”‚   â”œâ”€â”€ cardboard/               # ~1,750 images
â”‚   â”œâ”€â”€ glass/                   # ~1,750 images
â”‚   â”œâ”€â”€ metal/                   # ~1,750 images
â”‚   â”œâ”€â”€ paper/                   # ~1,750 images
â”‚   â”œâ”€â”€ plastic/                 # ~1,750 images
â”‚   â””â”€â”€ organic/                 # ~1,750 images
â”‚
â”œâ”€â”€ validation/                  # 15% of data
â”‚   â”œâ”€â”€ cardboard/               # ~375 images
â”‚   â”œâ”€â”€ glass/                   # ~375 images
â”‚   â”œâ”€â”€ metal/                   # ~375 images
â”‚   â”œâ”€â”€ paper/                   # ~375 images
â”‚   â”œâ”€â”€ plastic/                 # ~375 images
â”‚   â””â”€â”€ organic/                 # ~375 images
â”‚
â”œâ”€â”€ test/                        # 15% of data
â”‚   â””â”€â”€ (same structure)
â”‚
â”œâ”€â”€ raw/                         # Original downloaded datasets
â”‚   â”œâ”€â”€ trashnet/
â”‚   â”œâ”€â”€ taco/
â”‚   â””â”€â”€ kaggle_waste/
â”‚
â””â”€â”€ dataset_info.json            # Metadata and statistics
```

---

## ğŸ§ª Tests Directory Structure

```
tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ conftest.py                  # Pytest configuration
â”œâ”€â”€ test_model.py                # Model unit tests
â”œâ”€â”€ test_preprocessing.py        # Image preprocessing tests
â”œâ”€â”€ test_predictions.py          # Prediction accuracy tests
â”œâ”€â”€ test_data_loading.py         # Data pipeline tests
â””â”€â”€ fixtures/                    # Test data
    â”œâ”€â”€ sample_plastic.jpg
    â”œâ”€â”€ sample_glass.jpg
    â””â”€â”€ sample_metal.jpg
```

---

## ğŸ““ Notebooks Directory (Optional)

```
notebooks/
â”œâ”€â”€ 01_data_exploration.ipynb    # EDA and visualization
â”œâ”€â”€ 02_model_training.ipynb      # Interactive training
â”œâ”€â”€ 03_evaluation.ipynb          # Model performance analysis
â”œâ”€â”€ 04_error_analysis.ipynb      # Misclassification study
â””â”€â”€ 05_experiments.ipynb         # Model experiments
```

---

## ğŸ¨ Assets Directory

```
assets/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ logo.png                 # EcoSort logo
â”‚   â”œâ”€â”€ banner.jpg               # Repository banner
â”‚   â”œâ”€â”€ icon.png                 # App icon
â”‚   â””â”€â”€ screenshots/
â”‚       â”œâ”€â”€ demo_1.png
â”‚       â”œâ”€â”€ demo_2.png
â”‚       â””â”€â”€ results.png
â”‚
â”œâ”€â”€ diagrams/
â”‚   â”œâ”€â”€ architecture.png         # Model architecture diagram
â”‚   â”œâ”€â”€ workflow.png             # Project workflow
â”‚   â””â”€â”€ data_flow.png            # Data pipeline
â”‚
â””â”€â”€ presentations/
    â””â”€â”€ ecosort_pitch.pdf        # Project presentation
```

---

## ğŸš€ Deployment Files (Future)

```
deployment/                      # Future deployment configs
â”œâ”€â”€ Dockerfile                   # Docker container
â”œâ”€â”€ docker-compose.yml           # Multi-container setup
â”œâ”€â”€ app.py                       # Flask/FastAPI web app
â”œâ”€â”€ mobile/
â”‚   â”œâ”€â”€ android/                 # Android app
â”‚   â””â”€â”€ ios/                     # iOS app
â””â”€â”€ cloud/
    â”œâ”€â”€ aws_lambda.py            # AWS Lambda function
    â””â”€â”€ gcp_function.py          # Google Cloud Function
```

---

## ğŸ“¦ File Size Guidelines

To keep the repository clean and manageable:

| File Type | Max Size | Location | Git Tracking |
|-----------|----------|----------|--------------|
| Python code | < 100 KB | Root/tests | âœ… Tracked |
| Documentation | < 500 KB | docs/ | âœ… Tracked |
| Model files | < 50 MB | models/ | âŒ Ignored |
| Dataset images | Any | data/ | âŒ Ignored |
| Notebooks | < 5 MB | notebooks/ | âš ï¸ Optional |

---

## ğŸ”„ Typical Development Workflow

1. **Setup**: Clone repo â†’ Install dependencies â†’ Download datasets
2. **Development**: Create branch â†’ Make changes â†’ Test locally
3. **Training**: Organize data â†’ Train model â†’ Evaluate performance
4. **Testing**: Run unit tests â†’ Test with real images â†’ Fix issues
5. **Documentation**: Update README â†’ Add comments â†’ Create examples
6. **Contribution**: Commit changes â†’ Push to fork â†’ Create PR

---

## ğŸ“‹ Checklist for New Contributors

- [ ] Clone repository
- [ ] Read README.md and SETUP.md
- [ ] Install dependencies from requirements.txt
- [ ] Download at least one dataset
- [ ] Run data_preparation.py to setup structure
- [ ] Run ecosort_model.py to verify installation
- [ ] Try ecosort_demo.py with sample images
- [ ] Read CONTRIBUTING.md
- [ ] Choose an issue or feature to work on

---

## ğŸ”— Related Files

| If you need... | Look at... |
|----------------|------------|
| Installation help | SETUP.md |
| Usage examples | README.md |
| Code guidelines | CONTRIBUTING.md |
| Model details | ecosort_model.py |
| Demo usage | ecosort_demo.py |
| Dataset info | data_preparation.py |

---

## ğŸ“ Maintenance

**Regular Updates Needed**:
- Dataset links (if broken)
- Package versions in requirements.txt
- Model performance metrics
- Documentation accuracy
- Screenshot updates

**Version Control**:
- Use semantic versioning (v1.0.0)
- Tag releases on GitHub
- Maintain CHANGELOG.md

---

**Last Updated**: December 2025  
**Project Version**: 1.0.0